# 数据整理
- [create_data_file.py](prepare/create_data_file.py)

标准命名，同时生成数据目录`csv`
# 数据转换
- `torch`格式对接： [dataset](entity/dataset.py)
- `前置数据处理`: [transform](config/trans.py)
# 阶段操作
- [train](ops/train.py)
- [test](ops/test.py)
- [predict](ops/predict.py)
# 常用配置
- [config](config/config.py)
# 入口
- [entrance](entrance/entrance.py)
# 策略
由于训练过程中，发现样本存在相同图案，但是底色不同的情况，为了更好的抓住重点进行训练，采用如下两种方法进行调整。
- 灰度图

直接采用灰度图像进行训练，摒弃颜色影响
- 调权值

对于预测失败的样本，采用更高的权值，放大损失函数，以拟合预测失败的图片。<br>
该方法默认样本收集无误，只是特征样本上存在一定偏差，如果样本存在一定数量的错误样本，该方法也会拟合错误样本，该场景下不推荐使用。<br>
同样的，该方法容易过拟合，应在拟合程度较差的三色通道进行使用，以削减网络对于底色的依赖。<br>
# 结果
本次实验中，训练集拟合结果(>90%)不错，但是在测试集上的表现不佳(0.6~0.8)。<br>
分析原因在于下面几点
- 样本各分类样本数量不足
- 训练和测试样本存在偏差
- 网络方面或存在一定改进

由于样本的问题，简单样本之间或具备了隔离性，但是相同类型之间，却不具备扩展性。<br>
如果只是测试训练类型的样本，结果还行，但是对于单一类型的旋转、颜色、边框等变换检测，效果不尽人意。<br>
应当收集更多类型样本，或者进行数据增广，在剪裁、底色、边框等方面进行变换，以提高特征变换的检测。<br>
但是样本的局限，不宜过多进行数据增广， 主要根源还是在于单类样本类型的缺乏，模型学习了简单的分类特性，却不具备单一类型的扩展性，对于样本的变换缺乏一定泛化能力。<br>
同样的，应当适当的进行裁剪，以更好的进行特征提取，数据缺乏的情况下，通过剪裁(关键点或者部分关键点)，让网络对于关键部位以及非关键部位有一定的判断依据。<br>
总而言之，训练数据在样本数量、样本类型(颜色、局部、边框)上缺乏更多可学习信息，缺乏本质上的包容性，单一方面的去拟合，并不足以提高泛化能力，只是丢掉精度的碰运气。<br>


网络方面的话，前面使用连选3x3以提高感受野，局部采用`maxpooling`,对于高光或者黑暗的样本，容易抹杀局部的特征学习。<br>
后续急于降低图片尺寸，采用了`averagepooling`避免信息缺失，但是同样混淆了信息。<br>
对于本身尺寸就较小、加上样本特征更多在于棱角，连续的大感受野检测，容易混淆拐点等细微信息，也容易引入颜色等作为判断信息。<br>
而且`maxpooling`，对于高光或黑暗场景下，关键信息可能就此被过滤，更主要后续的`averagepooling`，对关键信息也有一定的搅浑水的嫌疑。<br>

总体来看，三角边框是否算作一种内聚的特征呢，类型34和35的区别在哪呢，褪色的广告牌无边框算啥分类呢？
分类是真的多，样本是真的少，底色、边框、角度、关键点等可提取的特征信息真的不多。<br>
这种情况下，训练的结果必然天然耦合，泛化能力不强，因为训练的数据的局限，无法泛化。<br>
无依据的泛化，就是瞎猜。
